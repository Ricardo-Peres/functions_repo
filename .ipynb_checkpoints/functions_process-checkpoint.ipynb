{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions\n",
    "## Process, apply homemade corrections, cuts, fits, general analysis scrips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions defined in this script and their description:\n",
    "* **<u>Corrections and extra variables</u>**:\n",
    "    * **FieldCorrection_lv_v1** - Given a data df, applyes the sapcial correction developed by Giovo in Jan'19 for low-field condition. Needs an external ```scale.txt``` file.\n",
    "    * **distancetosource** - given a data df and the position of the NG (1, 2 or 3), returns the df with an extra column with the distance to the source.\n",
    "* **<u>Apply LAX cuts</u>**:\n",
    "    * **processandcut** - apply lax cuts given a df and a list of valid cuts. Returns the tuple (df,df_cut)\n",
    "    * **XFiducialCylinder1T** - homemade 1T fiducial volume\n",
    "* **<u>Simple leakage scan scripts</u>**:\n",
    "    * **get_leakage_dts** - Computes the ratio and number of leakage for each r cut value in from dts. Needs 'dts', 'is_leakage' in df: leakage_number, leakage_number_err,leakage_ratio,leakage_ratio_err\n",
    "    * **get_leakage** - A generalization of the above script to a 1D scan of cut values comparing with a needed column in a df. A 'is_leakage' column is still needed!\n",
    "* **<u>Band fits</u>**:\n",
    "    * **gaussian** - ```a * np.exp(-(x-mu)**2 / (2*sigma**2))```\n",
    "    * **fit_function_SR0** - empirical model used in SR0 (4 params)\n",
    "    * **fit_function_SR1** - empirical model used in SR1 (5 params)\n",
    "    * **get_percentile_bin** - gets the counting percentile for a given bin. Needs\n",
    "    * **get_percentile_all** - given a df_cut, returns a dictionary with the computed percentiles (y value). Each key a percentile considered. Optional: percentiles to compute, 2D range and bins to consider. Default is cs1 vs log(cs2/cs1), accepts costum _x and _y.\n",
    "    * **get_bandfit_values_perc** - returns two list: list of tuned parameters, list of errors in parameters. Needs: percentiles dictionary (now only set to 5,50,95 percentiles), optional: fit_function (SR0 by default) and p0. Example: ```fit_values_rn, fit_errors_rn = get_fit_values(percentiles_rn)``` -> ```plt.plot(x,fit_function_SR0(x,fit_values[0][0],fit_values[0][1],fit_values[0][2],fit_values[0][3]),'g-',lw=3,label= '5th/95th percentile')```\n",
    "    * **get_gauss_bins** - given a hist2d, returns an complex array with the fits on each xbin. Used in process_gauss_df.\n",
    "    * **process_gauss_df** - given a df_cut, returns a pandas.df with x_mid, mu (value in yscale), mu+-2sigma and each errors to input into a gaussian model. Optional: _x, _y, range, bins (default is cs1 vs log(cs2/cs1) ).\n",
    "    * **get_bandfit_gauss** - returns the fit parameters and errors for a set of data when fitting to a function\n",
    "    * **get_bandfit_gauss_dict** - fits each line usually usefull: median, mu+2sigma, mu-2sigma\n",
    "* **<u>ER Leakage calculation - work in progress </u>**\n",
    "    * **NR_mean**, **NR_m2sig**, **NR_p2sig** - \n",
    "    * **get_bands_boolean** - returns a dataframe with three more columns, identifying in which band the event is\n",
    "    * **get_leakage_stats** - prints the stats for ER/NR leakage for given cs1 interval\n",
    "* **<u>Cut analysis</u>**:\n",
    "    * **get_cutaccept** - given 2 dataframes (df_1,df_2, a list of cuts to pre-apply, a cut and variable to study, the function plots the histogram of such variable before and after the cut_study and returns the acceptance of the cut in the variable designed range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Loading processing functions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrections and extra variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FieldCorrection_lv_v1(data, path):\n",
    "    scale = np.loadtxt('scale.txt')\n",
    "    print('Loaded r scale file.')\n",
    "    data_uniformity = data\n",
    "    L = int(len(data_uniformity.int_a_z_pax)/10)\n",
    "    hist, xbins, ybins, _ = plt.hist2d(data_uniformity['int_a_r_nn']**2, data_uniformity['int_a_z_pax'], bins=(100,10), \n",
    "                                       range=((0,2900),(-96.6, 0)), norm=matplotlib.colors.LogNorm(),\n",
    "                                       cmin = 1,alpha = 1)\n",
    "    plt.show()\n",
    "    print(ybins)\n",
    "    NaNs = np.isnan(hist)\n",
    "    hist[NaNs] = 0\n",
    "    Nans = np.isnan(hist)\n",
    "    hist_transpose = hist.transpose() \n",
    "\n",
    "    # hist -> (100, 10) entrate sull'asse z al variare di r \n",
    "    # hist_transpose -> (10,100) entrate sull'asse r al variare di z\n",
    "    # hist: primo riga r=0, secondo riga r=1, ... hist_traspose: primo riga z=-100, seconda riga z=-90, ...\n",
    "\n",
    "    xbins_center = [(xbins[i+1]+xbins[i])/2 for i in range(0, len(xbins)-1)]\n",
    "    ybins_center = [(ybins[i+1]+ybins[i])/2 for i in range(0, len(ybins)-1)]\n",
    "    r = np.zeros((10,10), dtype=float)\n",
    "    data_uniformity = data_uniformity.sort_values(by = ['int_a_z_pax'], ascending = True).reset_index(drop = True)\n",
    "    data_uniformity['int_a_r_correct'] = data_uniformity['int_a_r_nn']\n",
    "    data_uniformity['int_a_r_nn_squared'] = data_uniformity['int_a_r_nn']**2\n",
    "    r_zero = np.zeros((10,1), dtype=float)\n",
    "    r_zero = np.hstack((r_zero, r))\n",
    "    \n",
    "    k=0\n",
    "    j=0\n",
    "    control = 0\n",
    "    for i in tqdm(range(len(data_uniformity))):\n",
    "        #print('\\n', i)\n",
    "        while control == 0: #trova il bin di z_pax e copia la variabile che itera k -> row\n",
    "            if data_uniformity['int_a_z_pax'].iloc[i] <= ybins[k+1] and data_uniformity['int_a_z_pax'].iloc[i] >= ybins[k]:\n",
    "                row = k\n",
    "                control = 1\n",
    "            elif k==10:\n",
    "                break;\n",
    "            else:\n",
    "                k=k+1\n",
    "        control = 0\n",
    "        while control == 0: #definito il row, devo trovare dove appartiene r_nn (10% dei dati, 20% de dati,...). j -> col\n",
    "            if j==10 and data_uniformity['int_a_r_nn_squared'].iloc[i] > r_zero[k,j-1]:\n",
    "                col = j-1\n",
    "                data_uniformity['int_a_r_correct'].iloc[i] = data_uniformity['int_a_r_nn'].iloc[i]/scale[row, col]\n",
    "                break\n",
    "            if data_uniformity['int_a_r_nn_squared'].iloc[i] < r_zero[k,j+1] and data_uniformity['int_a_r_nn_squared'].iloc[i] > r_zero[k,j]:    \n",
    "                col = j\n",
    "                data_uniformity['int_a_r_correct'].iloc[i] = data_uniformity['int_a_r_nn'].iloc[i]/scale[row, col]\n",
    "                control = 1 \n",
    "            else:\n",
    "                j=j+1\n",
    "        j=0\n",
    "        k =0\n",
    "        control = 0\n",
    "    data_uniformity[['int_a_z_pax', 'int_a_r_nn', 'int_a_r_correct']].to_csv(path + '/int_a_r_correct', sep='\\t', \n",
    "                                                                         encoding='utf-8', index=False)\n",
    "    data['int_a_r_correct'] = data_uniformity['int_a_r_correct']\n",
    "        \n",
    "    hist_corretto, xbins_corretto, ybins_corretto, _ = plt.hist2d(data_uniformity['int_a_r_correct']**2, \n",
    "                                                              data_uniformity['int_a_z_pax'], bins=(50,6), \n",
    "                                                              range=((0,2900),(-96.6, 0)), norm=matplotlib.colors.LogNorm(),\n",
    "                                                              cmin = 1,alpha = 1)\n",
    "    plt.axvline(x=47.9**2, color='red', ls='--', label='TPC boundary')\n",
    "    plt.ylim(-96.6,0.0)\n",
    "    plt.xlabel('$r^2$  ($cm^2$)')\n",
    "    plt.ylabel('$z$ $(cm)$')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('post-SR1 field correction')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return data_uniformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distancetosource(df, pos):\n",
    "    if pos == 1:\n",
    "        source_position = (83.5, -39, -50)\n",
    "    elif pos == 2:\n",
    "        source_position = (31.6, 86.8, -50.)\n",
    "    elif pos == 3:\n",
    "        source_position = (-92.4, 0.0, -50.0)\n",
    "    else:\n",
    "        raise 'State the position of the NG: 1, 2 or 3.'\n",
    "\n",
    "    df['dts'] = ((source_position[0] - df['x_3d_nn']) ** 2 +\n",
    "             (source_position[1] - df['y_3d_nn']) ** 2 +\n",
    "             (source_position[2] - df['z_3d_nn']) ** 2) ** 0.5\n",
    "    #cutdistance = 111.5\n",
    "    #df['Cutdts'] = df['dts'] < cutdistance\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply LAX cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processandcut(df,cut_list):\n",
    "    print('Aplying cuts to data')\n",
    "    print('Process:')\n",
    "    for cut in (cut_list):\n",
    "        #print(cut.name())\n",
    "        df = cut.process(df)\n",
    "        print('Cut processed:',cut.name())\n",
    "\n",
    "    df_cut = df.copy()\n",
    "    print('=======//=======')\n",
    "    print('Cut them all!!')\n",
    "    for cut in cut_list:\n",
    "        name = cut.name()\n",
    "        print('------%s------' %name)\n",
    "        df_cut = cuts.selection(df_cut, df_cut[name], name)\n",
    "    #hax.cuts.history(df_cut)\n",
    "    return df, df_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def XFiducialCylinder1T(df):\n",
    "    #print('\\nProcessing and cutting FIducial1T\\n')\n",
    "    df['Cutfid1T'] = (df['z_3d_nn_tf'] > -92.9) & (df['z_3d_nn_tf'] < -9) & (df['r_3d_nn_tf'] < 36.94)\n",
    "    df = df[df['Cutfid1T'] == True]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple leakage scan scripts\n",
    "\n",
    "Scripts used to study the relations between the distance to source and the leakage: needs a 'dts' and 'is_leakage' columns. Iterates over a rscan in 'dts'. \n",
    "\n",
    "A generalization of the scripts to a 1D scan of cut values comparing with a needed column in a df is also presented. A 'is_leakage' column is still needed!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_leakage_dts(_data_cut,r_scan):\n",
    "    leakage_number = []\n",
    "    leakage_number_err =[]\n",
    "    \n",
    "    for r in r_scan:\n",
    "        N_is = len(_data_cut[(_data_cut['dts'] < r) &\n",
    "                             (_data_cut['is_leakage'])])\n",
    "        N_tot =len(_data_cut[(_data_cut['dts'] < r)])\n",
    "        #print(r,N_is, N_tot)\n",
    "        N_is_err = np.sqrt(N_is)\n",
    "        N_tot_err = np.sqrt(N_tot)\n",
    "\n",
    "        leakage_number.append(N_is)\n",
    "        leakage_number_err.append(N_is_err)\n",
    "        leakage_ratio.append(N_is/N_tot)\n",
    "        leakage_ratio_err.append(np.sqrt(np.power(N_is_err/N_tot,2) + np.power(N_is*N_tot_err/np.power(N_tot,2),2)))\n",
    "\n",
    "    leakage_number = np.array(leakage_number)\n",
    "    leakage_number_err = np.array(leakage_number_err)\n",
    "    leakage_ratio = np.array(leakage_ratio)\n",
    "    leakage_ratio_err = np.array(leakage_ratio_err)\n",
    "    \n",
    "    return leakage_number, leakage_number_err,leakage_ratio, leakage_ratio_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_leakage(df_cut, variable_to_test,scan_values):\n",
    "    _data_cut = df_cut\n",
    "    leakage_number = []\n",
    "    leakage_number_err =[]\n",
    "    \n",
    "    for r in scan_values:\n",
    "        N_is = len(_data_cut[(_data_cut['variable_to_test'] < r) &\n",
    "                             (_data_cut['is_leakage'])])\n",
    "        N_tot =len(_data_cut[(_data_cut['variable_to_test'] < r)])\n",
    "        #print(r,N_is, N_tot)\n",
    "        N_is_err = np.sqrt(N_is)\n",
    "        N_tot_err = np.sqrt(N_tot)\n",
    "\n",
    "        leakage_number.append(N_is)\n",
    "        leakage_number_err.append(N_is_err)\n",
    "        leakage_ratio.append(N_is/N_tot)\n",
    "        leakage_ratio_err.append(np.sqrt(np.power(N_is_err/N_tot,2) + np.power(N_is*N_tot_err/np.power(N_tot,2),2)))\n",
    "\n",
    "    leakage_number = np.array(leakage_number)\n",
    "    leakage_number_err = np.array(leakage_number_err)\n",
    "    leakage_ratio = np.array(leakage_ratio)\n",
    "    leakage_ratio_err = np.array(leakage_ratio_err)\n",
    "    \n",
    "    return leakage_number, leakage_number_err,leakage_ratio, leakage_ratio_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Band fits\n",
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(x, a, mu, sigma):\n",
    "    return a * np.exp(-(x-mu)**2 / (2*sigma**2))\n",
    "    #return np.exp(-np.power((x-mu),2)/(2*np.power(sigma,2))) / np.sqrt(2*np.pi*np.power(sigma,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_function_SR1(x,a,b,c,d,e):\n",
    "    ans = a*np.exp(-x/b) + c - d*x + e/x\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_function_SR0(x,a,b,c,d):\n",
    "    ans = a*np.exp(-x/b) + c + d*x\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentiles bin fit\n",
    "Bins on the x scale of a 2D histogram. The simple percentile of a bin needs a hist2d input (right now I'm a bit lazy, sorry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_percentile_bin(hist, xbinnumber, percentage): #gets the counting percentile for a given bin\n",
    "    ybinsize = hist[2][1]-hist[2][0]\n",
    "    ybins_middle = hist[2][:-1] + ybinsize/2\n",
    "    size = len(hist[0][xbinnumber])\n",
    "    cumsum = np.cumsum(hist[0][xbinnumber])\n",
    "    totalsum = cumsum[-1]\n",
    "    if totalsum == 0:\n",
    "        return None\n",
    "    for n in range(size):\n",
    "        nsum = cumsum[n]\n",
    "        perc = nsum/totalsum *100\n",
    "        if perc >= percentage-0.00001:\n",
    "            return ybins_middle[n]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_percentile_all(df_cut,percentsneeded = [5,95,50],_x = None, _y=None, perc_range = [[1,150],[0,3]], bins=50):\n",
    "    if (str(_x),str(_y)) == (None, None):\n",
    "        _x = df_cut['cs1']\n",
    "        _y = np.log10(df_cut['cs2_bottom'] / df_cut['cs1'])\n",
    "    hist = np.histogram2d(_x, _y,\n",
    "                          bins=bins,\n",
    "                          range = perc_range)\n",
    "    xbin_middle = hist[1][:-1] + (hist[1][1]-hist[1][0])/2\n",
    "    ans = {'bins':bins}\n",
    "    for percent in percentsneeded:\n",
    "        _perc_list = []\n",
    "        for xbin in range(len(hist[0])):\n",
    "            _perc__of_bin =get_percentile_bin(hist,xbin,percent)\n",
    "            if _perc__of_bin != None:\n",
    "                _perc_list.append([xbin_middle[xbin],_perc__of_bin])\n",
    "            else:\n",
    "                continue\n",
    "        ans[percent] = np.array(_perc_list)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bandfit_values_perc(percentiles,function = 'SR0', p0 = None):\n",
    "    xperc5 = percentiles[5][:,0]\n",
    "    xperc50 = percentiles[50][:,0]\n",
    "    xperc95 = percentiles[95][:,0]\n",
    "    yperc5 = percentiles[5][:,1]\n",
    "    yperc50 = percentiles[50][:,1]\n",
    "    yperc95 = percentiles[95][:,1]\n",
    "    \n",
    "    if function == 'SR0':\n",
    "        if p0 == None:\n",
    "            p0 = [28.12,0.687,1.38,-0.0021]\n",
    "        fit5 = curve_fit(fit_function_SR0,xperc5,yperc5,p0)\n",
    "        fit50 = curve_fit(fit_function_SR0,xperc50,yperc50,p0)\n",
    "        fit95 = curve_fit(fit_function_SR0,xperc95,yperc95,p0)\n",
    "\n",
    "    elif function == 'SR1':\n",
    "        if p0 == None:\n",
    "            p0 = [28.12,0.687,1.38,-0.0021,0.45]\n",
    "        fit5 = curve_fit(fit_function_SR1,xperc5,yperc5,p0)\n",
    "        fit50 = curve_fit(fit_function_SR1,xperc50,yperc50,p0)\n",
    "        fit95 = curve_fit(fit_function_SR1,xperc95,yperc95,p0)\n",
    "    else:\n",
    "        fit5 = curve_fit(function,xperc5,yperc5,p0=p0)\n",
    "        fit50 = curve_fit(function,xperc50,yperc50,p0=p0)\n",
    "        fit95 = curve_fit(function,xperc95,yperc95,p0=p0)\n",
    "        \n",
    "    L=[]\n",
    "    for fit in [fit5,fit50,fit95]:\n",
    "        l=[]\n",
    "        for v in fit[0]:\n",
    "            l.append(v)\n",
    "        L.append(l)\n",
    "    L2 = [] \n",
    "    for fit in [fit5,fit50,fit95]:\n",
    "        error = []\n",
    "        err = fit[1]\n",
    "        for i in range(len(fit[0])):\n",
    "            try:\n",
    "                error.append(np.absolute(err[i][i])**0.5)\n",
    "            except:\n",
    "                error.append(0.00)\n",
    "        L2.append(error)\n",
    "    return L, L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian bin fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gauss_bins(hist):\n",
    "    ylist = hist[2]\n",
    "    valuelist = hist[0]\n",
    "    ybinsize = ylist[1]-ylist[0]\n",
    "    ybins_middle = ylist[:-1] + ybinsize/2\n",
    "    fits =[]\n",
    "    for xbin in range(len(hist[1])-1):\n",
    "        _values = valuelist[xbin]\n",
    "        _cumsum = np.cumsum(_values)\n",
    "        _totalsum = _cumsum[-1]\n",
    "        _mean = np.sum(ybins_middle*_values)/_totalsum\n",
    "        _dev = np.sqrt(np.sum(np.power(ybins_middle-_mean,2))/(_totalsum-1))\n",
    "\n",
    "        _fitpar,_fiterr = curve_fit(gaussian,ybins_middle,_values,p0=[1,_mean,_dev])\n",
    "        _err = []\n",
    "        for i in range(len(_fiterr)):\n",
    "            _err.append(np.sqrt(np.absolute(_fiterr[i][i])))\n",
    "        #print(_fitpar, _err)\n",
    "        fits.append(np.array([np.array(_fitpar),np.array(_err)]))\n",
    "\n",
    "    return np.array(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_gauss_df(df_cut,_x = None, _y=None, bins=30, rang=[[5,150],[0,3]]):\n",
    "    if (_x,_y) == (None, None):\n",
    "        _x = df_cut['cs1']\n",
    "        _y = np.log10(df_cut['cs2_bottom'] / df_cut['cs1'])\n",
    "    hist = np.histogram2d(_x, _y,\n",
    "                          bins=bins, range = rang)\n",
    "    # Create a DataFrame to work with, first column is the middle of each x bin\n",
    "    xmid = hist[1][:-1] + (hist[1][1]-hist[1][0])/2\n",
    "    #print(len(xmid))\n",
    "    df = pd.DataFrame(xmid, columns=['x_mid'])\n",
    "    # Fit the values over y of each bin in x\n",
    "    _fits = get_gauss_bins(hist)\n",
    "    # Fill the DataFrame with the fit parameters\n",
    "    #print(_fits.shape)\n",
    "    df['mu'] = _fits[:,[0],[1]]\n",
    "    df['mu_err'] = np.absolute(_fits[:,[1],[1]])\n",
    "    df['sig'] = np.absolute(_fits[:,[0],[2]])\n",
    "    df['sig_err'] = np.absolute(_fits[:,[1],[2]])\n",
    "    df['mu+2sig'] = df['mu']+2*df['sig']\n",
    "    df['mu+2sig_err'] = np.sqrt(np.power(df['mu_err'],2) + np.power(2*df['sig_err'],2))\n",
    "    df['mu-2sig'] = df['mu']-2*df['sig']\n",
    "    df['mu-2sig_err'] = np.sqrt(np.power(df['mu_err'],2) + np.power(2*df['sig_err'],2))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bandfit_gauss(df_gauss,fit_function = fit_function_SR0,sigma = None, p0 = None): #,):\n",
    "    xdata = df_gauss['x_mid']\n",
    "    ydata = df_gauss['x_mid']\n",
    "    if p0 == None:\n",
    "        p0 = [28.12,0.687,1.38,-0.0021]\n",
    "    _fit_par, _fit_err = curve_fit(fit_function,xdata,ydata,p0=p0, sigma = sigma)\n",
    "    _error = []\n",
    "    for i in range(len(_fit_par)):\n",
    "            try:\n",
    "                _error.append(np.absolute(_fit_err[i][i])**0.5)\n",
    "            except:\n",
    "                raise 'Deu asneira no erro :('\n",
    "    return _fit_par, _error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bandfit_gauss_dict(df_gauss,fit_function = fit_function_SR0,sigma = None, p0 = None):\n",
    "    # Fit median:\n",
    "    med_fit, med_err = get_bandfit_gauss(df_gauss=df_gauss, fit_function = fit_function_SR0, sigma = df_gauss['mu_err'])\n",
    "    # Fit +2sigma:\n",
    "    plus2sig_fit, plus2sig_err = get_bandfit_gauss(df_gauss=df_gauss, fit_function = fit_function_SR0, sigma = df_gauss['mu+2sig_err'])\n",
    "    # Fit -2sigma\n",
    "    minus2sig_fit, minus2sig_err = get_bandfit_gauss(df_gauss=df_gauss, fit_function = fit_function_SR0, sigma = df_gauss['mu-2sig_err'])\n",
    "    # Put it all in a dict\n",
    "    fit_values = {'mu':[med_fit,med_err],'p2sig':[plus2sig_fit, plus2sig_err],'m2sig':[minus2sig_fit, minus2sig_err]}\n",
    "    return fit_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ER Leakage calculation - work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def NR_mean(x,fit_values):\n",
    "    a,b,c,d = fit_values[1][0],fit_values[1][1],fit_values[1][2],fit_values[1][3]\n",
    "    return fit_function_SR0(x,a,b,c,d)\n",
    "\n",
    "def NR_m2sig(x,fit_values):\n",
    "    a,b,c,d = fit_values[0][0],fit_values[0][1],fit_values[0][2],fit_values[0][3]\n",
    "    return fit_function_SR0(x,a,b,c,d)\n",
    "\n",
    "def NR_p2sig(x,fit_values):\n",
    "    a,b,c,d = fit_values[2][0],fit_values[2][1],fit_values[2][2],fit_values[2][3]\n",
    "    return fit_function_SR0(x,a,b,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bands_boolean(df_cut):\n",
    "    df_cut['up_m2sig'] = (np.log10(df_cut['cs2_bottom'] / df_cut['cs1']) > NR_m2sig(df_cut['cs1']))\n",
    "    df_cut['up_mean'] = (np.log10(df_cut['cs2_bottom'] / df_cut['cs1']) > NR_mean(df_cut['cs1']))\n",
    "    df_cut['up_p2sig'] = (np.log10(df_cut['cs2_bottom'] / df_cut['cs1']) > NR_p2sig(df_cut['cs1']))\n",
    "    return df_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_leakage_stats(df_cut, lowcs1,highcs1):\n",
    "    counts = len(df_cut[(df_cut['up_p2sig']==False) &\n",
    "                     (df_cut['up_mean']==False) &\n",
    "                     (df_cut['up_m2sig']==True) &\n",
    "                        (df_cut['cs1'] > lowcs1) &\n",
    "                        (df_cut['cs1'] < highcs1)])\n",
    "    total = len(df_cut[(df_cut['up_m2sig']==True)&\n",
    "                       (df_cut['cs1'] > lowcs1) &\n",
    "                       (df_cut['cs1'] < highcs1)])\n",
    "\n",
    "    error = np.sqrt(np.power(np.sqrt(counts)/total,2) + np.power((counts * np.sqrt(total))/np.power(total,2),2))\n",
    "\n",
    "    print('For %d < cs1 < %d pe\\nTotal ER events above NR-2sig: %d\\n\\\n",
    "    Total ER events above NR-2sig and bellow NRmean (leakage): %d\\n\\\n",
    "    Leakage fraction: %d/%d=%.8f +/- %.8f' %(lowcs1,highcs2,total,counts,counts,total,counts/total,error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cutaccept(df_1, df_2, cut_study,cut_ignore,variable_to_plot, binnrb, plot_hist):\n",
    "    from statsmodels.stats.proportion import proportion_confint\n",
    "    binomial_error_method = 'wilson'\n",
    "    binomial_alpha = 0.68\n",
    "    \n",
    "    if variable_to_plot == 'cs1':\n",
    "        rng = [0,200]\n",
    "    elif variable_to_plot == 'cs2':\n",
    "        rng = [10, 7000]\n",
    "    else:\n",
    "        rng = None\n",
    "        \n",
    "    for _cut in cut_ignore:\n",
    "        df_1 = df_1[df_1[_cut] == True]\n",
    "        df_2 = df_2[df_1[_cut] == True]\n",
    "        \n",
    "    hist_1 = plt.hist( df_1['%s' %variable_to_plot],\n",
    "                   bins = binnrb, range = rng, \n",
    "                   histtype = 'step',\n",
    "                  label = 'no cuts')\n",
    "\n",
    "    hist_1_cut = plt.hist( df_1[df_1['%s' %cut_study]]['%s' %variable_to_plot],\n",
    "                   bins = binnrb, range = rng, \n",
    "                   histtype = 'step',\n",
    "                  label = '%s'%cut_study)\n",
    "\n",
    "    hist_1_y = hist_1[0]\n",
    "    hist_1_cut_y = hist_1_cut[0]\n",
    "\n",
    "    accept_1_y = hist_1_cut_y/hist_1_y\n",
    "    accept_1_x = hist_1[1][:-1]\n",
    "    \n",
    "    erro_1 = np.sqrt(np.power((np.sqrt(hist_1_cut_y)/hist_1_y),2) + \\\n",
    "                       np.power(hist_1_cut_y*np.sqrt(hist_1_y)/np.power(hist_1_y,2),2))\n",
    "    #sim_accept_y = np.append(sim_accept_y,sim_accept_y[-1])\n",
    "    \n",
    "    error_down,error_up = proportion_confint(hist_1_cut_y, hist_1_y, method=binomial_error_method, alpha=binomial_alpha)\n",
    "    #print (error_up,error_down)\n",
    "    error_1 = np.array([error_down,error_up])\n",
    "    \n",
    "    #sim_accept_error = sim_accept_error[1]-sim_accept_error[0]\n",
    "    #sim_accept_smooth_x = np.linspace(sim_accept_x[0], sim_accept_x[-1], 500)\n",
    "    #sim_accept_smooth_y = spline(sim_accept_x,sim_accept_y,sim_accept_smooth_x)\n",
    "    \n",
    "    #ax1 = plt.plot(sim_accept_smooth_x,sim_accept_smooth_y)\n",
    "    \n",
    "    hist_2 = plt.hist( df_2['%s' %variable_to_plot],\n",
    "                   bins = binnrb, range = rng, \n",
    "                   histtype = 'step',\n",
    "                  label = 'no cuts')\n",
    "\n",
    "    hist_2_cut = plt.hist( df_2[df_2['%s' %cut_study]]['%s' %variable_to_plot],\n",
    "                   bins = binnrb, range = rng, \n",
    "                   histtype = 'step',\n",
    "                  label = '%s'%cut_study)\n",
    "    \n",
    "    hist_2_y = hist_2[0]\n",
    "    hist_2_cut_y = hist_2_cut[0]\n",
    "\n",
    "    accept_2_y = hist_2_cut_y/hist_2_y\n",
    "    accept_2_x = hist_2[1][:-1]\n",
    "\n",
    "    #data_accept_y = np.append(data_accept_y,data_accept_y[-1])\n",
    "    \n",
    "    error_down,error_up = proportion_confint(hist_2_cut_y, hist_2_y, method=binomial_error_method, alpha=binomial_alpha)\n",
    "    \n",
    "    erro_2 = np.sqrt(np.power((np.sqrt(hist_2_cut_y)/hist_2_y),2) + \\\n",
    "                       np.power(hist_2_cut_y*np.sqrt(hist_2_y)/np.power(hist_2_y,2),2))\n",
    "    \n",
    "    error_2 = np.array([error_down,error_up])\n",
    "    #data_accept_smooth_x = np.linspace(data_accept_x[0], data_accept_x[-1], 1000)\n",
    "    #data_accept_smooth_y = spline(data_accept_x,data_accept_y,data_accept_smooth_x)\n",
    "    if plot_hist == True:\n",
    "        plt.show()\n",
    "    #ax2 = plt.plot(data_accept_smooth_x,data_accept_smooth_y)\n",
    "    \n",
    "    #return (sim_accept_smooth_x,sim_accept_smooth_y,data_accept_smooth_x,data_accept_smooth_y)\n",
    "    return accept_1_x, accept_1_y, error_1, accept_2_x, accept_2_y, error_2, erro_1 , erro_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
